# mutliple_python_file_dag
# assumed directory structure
# dags/
#   my_dag_for_script_1_and_2.py
#   tasks/
#        script1.py
#        script2.py

from airflow import DAG
from airflow.operators import PythonOperator
import script.file1
import script.file2

with DAG(
    'my_dag_for_script_1_and_2',
    default_args={
        'owner': 'me',
        'start_date': datetime(â€¦),
        â€¦,
    }, 
    schedule_interval='8 * * * *',
) as dag:
    task_1 = PythonOperator(
        task_id='task_1', 
        python_callable=script1.function_in_script1,
    )
    task_2 = PythonOperator(
        task_id='task_2', 
        python_callable=script2.function_in_file2,
    )
    task_1 >> task_2
